{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amy/.local/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/home/amy/.local/lib/python2.7/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#this file has all my utility functions -- although I'm reproducing the important ones below\n",
    "from glm_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#magic numbers 6 and 9 come from cross validation to find best possible lag and offet. Note that was done for the natural \n",
    "#scenes stimulus so might not be the best here.\n",
    "\n",
    "def arrange_data_glm(dff_traces, images, stim_table):\n",
    "\t#declare a dictionary of empty lists for each cell trace, \n",
    "\t#and a list for the stimulus\n",
    "\tdata = []\n",
    "\tstim_array = []\n",
    "\tim_array = []\n",
    "\n",
    "\t#average each trace over the presentation of each stimulus\n",
    "\tfor index, row in stim_table.iterrows():\n",
    "\t    stim_array.append(images[row['frame']])\n",
    "\t    im_array.append(row['frame'])\n",
    "\n",
    "\t    try:\n",
    "\t    \tdata.append(np.mean(dff_traces[:, row['start'] + 6 :row['start'] + 9], axis = 1)) #/ np.mean(dff_traces[:, row['start'] : row['start'] - 30], axis = 1) )\n",
    "\t    except:\n",
    "\t    \tdata.append(np.mean(dff_traces[:, row['start']+ 6:row['end']], axis = 1))\n",
    "\tstim_array = np.array(stim_array)\n",
    "\t#stim_array = stim_array[:, 0:10]\n",
    "\n",
    "\tdata = np.array(data)\n",
    "\n",
    "\treturn data, stim_array, im_array\n",
    "\n",
    "def download_data(region, cre_line, stimulus = None):\n",
    "\t'''\n",
    "\tregion = [reg1, reg2, ...]\n",
    "\tcre_line = [line1, line2, ...]\n",
    "\t'''\n",
    "\tboc = BrainObservatoryCache(manifest_file='boc/manifest.json')\n",
    "\tecs = boc.get_experiment_containers(targeted_structures=region, cre_lines=cre_line)\n",
    "\n",
    "\tec_ids = [ ec['id'] for ec in ecs ]\n",
    "\n",
    "\texp = boc.get_ophys_experiments(experiment_container_ids=ec_ids)\n",
    "\n",
    "\tif stimulus == None:\n",
    "\t\texp = boc.get_ophys_experiments(experiment_container_ids=ec_ids)\n",
    "\n",
    "\telse:\n",
    "\t\texp = boc.get_ophys_experiments(experiment_container_ids=ec_ids, stimuli = stimulus)\n",
    "\n",
    "\n",
    "\texp_id_list = [ec['id'] for ec in exp]\n",
    "\n",
    "\tdata_set = {exp_id:boc.get_ophys_experiment_data(exp_id) for exp_id in exp_id_list}\n",
    "\n",
    "\treturn data_set \n",
    "\n",
    "def get_data(data_set, stimulus):\n",
    "\t'''\n",
    "\treturns dff, images, stim_table\n",
    "\t'''\n",
    "\n",
    "\ttime, dff_traces = data_set.get_dff_traces()\n",
    "\n",
    "\ttry:\n",
    "\t\timages = data_set.get_stimulus_template(stimulus)\n",
    "\texcept:\n",
    "\t\tprint \"No stimulus template...\"\n",
    "\t\timages = None\n",
    "\n",
    "\tstim_table = data_set.get_stimulus_table(stimulus)\n",
    "\n",
    "\treturn dff_traces, images, stim_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boc = BrainObservatoryCache(manifest_file='boc/manifest.json')\n",
    "\n",
    "regions = ['VISp']#, 'VISpm', 'VISl', 'VISal']\n",
    "lines =  ['Cux2-CreERT2']#, 'Rbp4-Cre', 'Rorb-IRES2-Cre'] \n",
    "\n",
    "\n",
    "#this dataset just has the locally sparse noise data from layer 2/3 of primary visual cortex\n",
    "data_set = download_data(regions, lines, [stim_info.LOCALLY_SPARSE_NOISE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[501773889,\n",
       " 504642019,\n",
       " 502634578,\n",
       " 501337989,\n",
       " 501717543,\n",
       " 510174759,\n",
       " 501474098,\n",
       " 501254258,\n",
       " 502974807,\n",
       " 505143581,\n",
       " 500855614,\n",
       " 509644421]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are the IDs of the different datasets that have locally sparse noise \n",
    "#stimulus data, in layer 2/3 of primary visual cortex\n",
    "\n",
    "data_set.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.locally_sparse_noise import LocallySparseNoise\n",
    "\n",
    "\n",
    "#here we get the RF's that allen computed, the stimulus images, and the dff data. \n",
    "#This takes a while to run, which is why I'm only doing it for one of the datasets \n",
    "#(which you can roughly think of as being a single mouse)\n",
    "\n",
    "key = data_set.keys()[0]\n",
    "\n",
    "#the line below literally takes forever, only uncomment this if you really care about the lsn stimulus\n",
    "lsn  = LocallySparseNoise(data_set[key])\n",
    "\n",
    "dff, images, stim_table = get_data(data_set[key], stim_info.LOCALLY_SPARSE_NOISE)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we plot the receptive fields which AIBS computed\n",
    "\n",
    "n_cells = lsn.receptive_field.shape[2]\n",
    "\n",
    "fig = plt.figure(figsize = [10, 100] )\n",
    "i = 1\n",
    "for n in range(n_cells):\n",
    "    ax = plt.subplot(np.ceil(n_cells/ 2.) + 1, 2, i)\n",
    "\n",
    "    rf = np.concatenate((lsn.receptive_field[:,:,i -1, 0], np.zeros([lsn.receptive_field.shape[0], 10]), lsn.receptive_field[:,:,i -1, 1]), axis = 1)\n",
    "\n",
    "    plt.imshow(rf, 'PuRd')\n",
    "    plt.axis('off')\n",
    "\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here's where we get the tensors which are useful for fitting models\n",
    "\n",
    "data, stim_array, _ = arrange_data_glm(dff, images, stim_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data is n_timepoints by n_neurons. stim_array is n_timepoints by im_y by im_x\n",
    "\n",
    "print data.shape, stim_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(stim_array[0], cmap = 'Greys')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
